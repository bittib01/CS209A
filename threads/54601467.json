{
  "question": {
    "tags": [
      "java",
      "tomcat",
      "spark-java"
    ],
    "owner": {
      "account_id": 7800807,
      "reputation": 167,
      "user_id": 5900323,
      "user_type": "registered",
      "accept_rate": 67,
      "profile_image": "https://www.gravatar.com/avatar/9bf90ff55de6639aec3ab1c82905ed27?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Preethi Jha",
      "link": "https://stackoverflow.com/users/5900323/preethi-jha"
    },
    "is_answered": false,
    "view_count": 554,
    "answer_count": 1,
    "score": 2,
    "last_activity_date": 1764953940,
    "creation_date": 1549667389,
    "last_edit_date": 1549942778,
    "question_id": 54601467,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/54601467/tomcat-fails-to-load-java-spark-application",
    "title": "Tomcat fails to load Java Spark application",
    "body": "<p>This issue does not relate to Apache Spark, but the Java web framework called Spark.</p>\n\n<p><a href=\"https://i.sstatic.net/cdC1G.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.sstatic.net/cdC1G.png\" alt=\"enter image description here\"></a>It's a legacy application of ours which uses Spark Java. When I am trying to deploy in Tomcat it throws the error of not finding Sparkfilter. Where should I check for resolving this issue?</p>\n\n<p>web.xml </p>\n\n<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" id=\"WebApp_ID\" version=\"3.0\"&gt;\n   &lt;filter&gt;\n   &lt;filter-name&gt;SparkFilter&lt;/filter-name&gt;\n   &lt;filter-class&gt;spark.servlet.SparkFilter&lt;/filter-class&gt;\n   &lt;init-param&gt;\n     &lt;param-name&gt;applicationClass&lt;/param-name&gt;\n     &lt;param-value&gt;com.example.resource.Spark&lt;/param-value&gt;\n   &lt;/init-param&gt;\n &lt;/filter&gt;\n\n &lt;filter-mapping&gt;\n   &lt;filter-name&gt;SparkFilter&lt;/filter-name&gt;\n   &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n &lt;/filter-mapping&gt;\n    &lt;listener&gt;       \n      &lt;listener-class&gt;\n         com.example.utilities.PropertiesLoader\n      &lt;/listener-class&gt;\n   &lt;/listener&gt; \n&lt;/web-app&gt;\n</code></pre>\n\n<p>Error in catalina.out</p>\n\n<pre><code>java.lang.NullPointerException\n    at com.example.resource.Spark.init(Spark.java:121)\n    at spark.servlet.SparkFilter.init(SparkFilter.java:61)\n    at org.apache.catalina.core.ApplicationFilterConfig.initFilter(ApplicationFilterConfig.java:285)\n    at org.apache.catalina.core.ApplicationFilterConfig.getFilter(ApplicationFilterConfig.java:266)\n    at org.apache.catalina.core.ApplicationFilterConfig.&lt;init&gt;(ApplicationFilterConfig.java:108)\n    at org.apache.catalina.core.StandardContext.filterStart(StandardContext.java:4657)\n    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5304)\n    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\n    at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:754)\n    at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:730)\n    at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:734)\n    at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1140)\n    at org.apache.catalina.startup.HostConfig$DeployDirectory.run(HostConfig.java:1875)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\n</code></pre>\n\n<p>I see pom.xml includes the Spark framework. What else should i check to resolve this?</p>\n"
  },
  "answers": [
    {
      "owner": {
        "account_id": 188643,
        "reputation": 11,
        "user_id": 427481,
        "user_type": "registered",
        "profile_image": "https://www.gravatar.com/avatar/72702eaeb0e1267d75ed28dcbdcdda1a?s=256&d=identicon&r=PG",
        "display_name": "Curlywurly",
        "link": "https://stackoverflow.com/users/427481/curlywurly"
      },
      "is_accepted": false,
      "score": 0,
      "last_activity_date": 1665723354,
      "creation_date": 1665723354,
      "answer_id": 74064465,
      "question_id": 54601467,
      "content_license": "CC BY-SA 4.0",
      "body": "<p>I had also problems starting my sparkjava service in Tomcat 10.\ncatalina.out shows</p>\n<pre><code>    org.apache.catalina.core.StandardContext.startInternal One or more Filters failed to start. Full details will be found in the appropriate container log file\n    org.apache.catalina.core.StandardContext.startInternal Context [/some-service] startup failed due to previous errors\n</code></pre>\n<p>and localhost.2022.10.13.log shows</p>\n<pre><code>    13-Oct-2022 22:07:34.374 SCHWERWIEGEND [Catalina-utility-2] org.apache.catalina.core.StandardContext.filterStart Ausnahme beim Starten des Filters [SparkFilter]\n    java.lang.ClassCastException: class spark.servlet.SparkFilter cannot be cast to class jakarta.servlet.Filter (spark.servlet.SparkFilter is in unnamed module of loader org.apache.catalina.loader.ParallelWebappClassLoader @41824418; jakarta.servlet.Filter is in unnamed module of loader java.net.URLClassLoader @4e1d422d)\n</code></pre>\n<p>I stepped back to Tomcat 9 ... that worked for me.</p>\n"
    }
  ],
  "question_comments": [],
  "answer_comments": {
    "74064465": []
  }
}