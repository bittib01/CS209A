{
  "question": {
    "tags": [
      "java",
      "apache-spark",
      "debugging",
      "java-17"
    ],
    "owner": {
      "account_id": 8250123,
      "reputation": 69,
      "user_id": 14243573,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/6a37a533ce149ee1471924ebfcbabb97?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Desk Reference",
      "link": "https://stackoverflow.com/users/14243573/desk-reference"
    },
    "is_answered": false,
    "view_count": 134,
    "answer_count": 0,
    "score": 0,
    "last_activity_date": 1742442305,
    "creation_date": 1742442305,
    "question_id": 79521858,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79521858/spark-upgrade-java-lang-noclassdeffounderror-could-not-initialize-class-org-a",
    "title": "Spark upgrade - java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.sql.catalyst.expressions.VirtualColumn$",
    "body": "<p>after upgrading my application to JDK 17 and Spark to 3.3.1, I encountered the following error:</p>\n<pre><code>java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.sql.catalyst.expressions.VirtualColumn$\n        at org.apache.spark.sql.catalyst.analysis.Analyzer.&lt;init&gt;(Analyzer.scala:1675)\n        at org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1.&lt;init&gt;(BaseSessionStateBuilder.scala:182)\n        at org.apache.spark.sql.internal.BaseSessionStateBuilder.analyzer(BaseSessionStateBuilder.scala:182)\n        at org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$build$2(BaseSessionStateBuilder.scala:360)\n        at org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:87)\n...\nCaused by:\n        java.lang.ExceptionInInitializerError: Exception java.lang.ExceptionInInitializerError [in thread &quot;Test worker&quot;]\n            at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:107)\n            at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parseMultipartIdentifier(ParseDriver.scala:67)\n            at org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute$.apply(unresolved.scala:161)\n            at org.apache.spark.sql.catalyst.expressions.VirtualColumn$.&lt;init&gt;(namedExpressions.scala:436)\n            at org.apache.spark.sql.catalyst.expressions.VirtualColumn$.&lt;clinit&gt;(namedExpressions.scala)\n            at org.apache.spark.sql.catalyst.analysis.Analyzer.&lt;init&gt;(Analyzer.scala:1675)\n            at org.apache.spark.sql.internal.BaseSessionStateBuilder$$anon$1.&lt;init&gt;(BaseSessionStateBuilder.scala:182)\n            at org.apache.spark.sql.internal.BaseSessionStateBuilder.analyzer(BaseSessionStateBuilder.scala:182)\n            at org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$build$2(BaseSessionStateBuilder.scala:360)\n            at org.apache.spark.sql.internal.SessionState.analyzer$lzycompute(SessionState.scala:87)\n            at org.apache.spark.sql.internal.SessionState.analyzer(SessionState.scala:87)\n            at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\n\n</code></pre>\n<p>Does anyone know about this error before and have resolution for this?</p>\n<p>I am using Jackson 2.18.</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}