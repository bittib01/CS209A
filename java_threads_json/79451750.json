{
  "question": {
    "tags": [
      "java",
      "google-bigquery",
      "google-cloud-dataflow",
      "apache-beam",
      "batch-processing"
    ],
    "owner": {
      "account_id": 29092734,
      "reputation": 9,
      "user_id": 22286198,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/aed8a6bd36ba979f24b0705431f90bbd?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Insecupa",
      "link": "https://stackoverflow.com/users/22286198/insecupa"
    },
    "is_answered": false,
    "view_count": 98,
    "answer_count": 2,
    "score": -1,
    "last_activity_date": 1745327878,
    "creation_date": 1739975913,
    "question_id": 79451750,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79451750/gcp-batch-dataflow-records-dropped-while-inserting-to-bigquery",
    "title": "GCP Batch Dataflow - Records Dropped while inserting to BigQuery",
    "body": "<p>Im using GCP Batch Dataflow to process data that im picking from a table. The input here is table data - where im using a query in Java to get the data.</p>\n<p>After processing, when I'm trying to insert the rows - Say 10 Complete records -</p>\n<p>If 1 records has an issue while inserting to BigQuery - That is no issue in processing. ( Ex - Datatype issue while inserting to Table ) - This record is being dropped - With the exact error reason but this is triggering more records to be dropped randomly. 1 or more records are dropped randomly -</p>\n<p>Error Reason being &quot;stopped&quot; - Thought this was due to inappropriate error handling - but couldn't make the code work.</p>\n<p>Do let me know if you have any suggestions.</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}