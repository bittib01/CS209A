{
  "question": {
    "tags": [
      "java",
      "apache-flink"
    ],
    "owner": {
      "account_id": 30266766,
      "reputation": 1,
      "user_id": 23195484,
      "user_type": "registered",
      "profile_image": "https://lh3.googleusercontent.com/a/ACg8ocKB7rkwL-bAosNbKvJsDHPvCUk3RFJ5fThauRtusOwoK0s=k-s256",
      "display_name": "Mibin",
      "link": "https://stackoverflow.com/users/23195484/mibin"
    },
    "is_answered": false,
    "view_count": 460,
    "answer_count": 0,
    "score": 0,
    "last_activity_date": 1732748398,
    "creation_date": 1725016461,
    "last_edit_date": 1725017562,
    "question_id": 78931702,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/78931702/flink-1-19-0-could-not-find-any-factory-for-identifier-hive-that-implements",
    "title": "Flink 1.19.0. Could not find any factory for identifier &#39;hive&#39; that implements &#39;org.apache.flink.table.delegation.ParserFactory&#39; in the classpath",
    "body": "<p>Created small sql application in flink .\nRead data from kafka and write into hive.</p>\n<p>When application start, it create connect to kafka, create catalog, set hive dialect and execute create table in hive.\nWhen execute CREATE HIVE TABLE in flink i get error:</p>\n<pre class=\"lang-java prettyprint-override\"><code>java.util.concurrent.CompletionException: org.apache.flink.client.deployment.application.ApplicationExecutionException: Could not execute application.\n  at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292) ~[?:1.8.0_412]\n  at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308) ~[?:1.8.0_412]\n  at java.util.concurrent.CompletableFuture.uniCompose(CompletableFuture.java:957) ~[?:1.8.0_412]\n  at java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:940) ~[?:1.8.0_412]\n  at java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:488) ~[?:1.8.0_412]\n  at java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:1990) ~[?:1.8.0_412]\n  at org.apache.flink.client.deployment.application.ApplicationDispatcherBootstrap.runApplicationEntryPoint(ApplicationDispatcherBootstrap.java:337) ~[flink-dist-1.19.0.jar:1.19.0]\n  at org.apache.flink.client.deployment.application.ApplicationDispatcherBootstrap.lambda$runApplicationAsync$2(ApplicationDispatcherBootstrap.java:254) ~[flink-dist-1.19.0.jar:1.19.0]\n  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_412]\n  at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_412]\n  at org.apache.flink.runtime.concurrent.pekko.ActorSystemScheduledExecutorAdapter$ScheduledFutureTask.run(ActorSystemScheduledExecutorAdapter.java:172) ~[?:?]\n  at org.apache.flink.runtime.concurrent.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-dist-1.19.0.jar:1.19.0]\n  at org.apache.flink.runtime.concurrent.ClassLoadingUtils.lambda$withContextClassLoader$0(ClassLoadingUtils.java:41) ~[flink-dist-1.19.0.jar:1.19.0]\n  at org.apache.pekko.dispatch.TaskInvocation.run(AbstractDispatcher.scala:59) [flink-rpc-akka52c5a613-0102-42f6-86ff-a2a04d0f7629.jar:1.19.0]\n  at org.apache.pekko.dispatch.ForkJoinExecutorConfigurator$PekkoForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:57) [flink-rpc-akka52c5a613-0102-42f6-86ff-a2a04d0f7629.jar:1.19.0]\n  at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289) [?:1.8.0_412]\n  at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056) [?:1.8.0_412]\n  at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692) [?:1.8.0_412]\n  at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175) [?:1.8.0_412]\nCaused by: org.apache.flink.client.deployment.application.ApplicationExecutionException: Could not execute application.\n  ... 13 more\nCaused by: org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Could not find any factory for identifier 'hive' that implements 'org.apache.flink.table.delegation.ParserFactory' in the classpath.\n\nAvailable factory identifiers are:\n\n\n  at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:372) ~[flink-dist-1.19.0.jar:1.19.0]\n  at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:222) ~[flink-dist-1.19.0.jar:1.19.0]\n  at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:108) ~[flink-dist-1.19.0.jar:1.19.0]\n  at org.apache.flink.client.deployment.application.ApplicationDispatcherBootstrap.runApplicationEntryPoint(ApplicationDispatcherBootstrap.java:301) ~[flink-dist-1.19.0.jar:1.19.0]\n  ... 12 more\nCaused by: org.apache.flink.table.api.ValidationException: Could not find any factory for identifier 'hive' that implements 'org.apache.flink.table.delegation.ParserFactory' in the classpath.\n</code></pre>\n<p>Java code:</p>\n<pre class=\"lang-java prettyprint-override\"><code>package org.my.nrt;\n\nimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\nimport org.apache.flink.table.api.SqlDialect;\nimport org.apache.flink.table.api.bridge.java.StreamTableEnvironment;\n\npublic class Main {\n    public static void main(String[] args) {\n        String createCatalog = &quot;CREATE CATALOG hive WITH (\\n&quot; +\n                &quot;  'type' = 'hive',\\n&quot; +\n                &quot;  'hive-conf-dir' = '/etc/hive/conf'\\n&quot; +\n                &quot;);&quot;;\n        String useCatalog = &quot;USE CATALOG hive;&quot;;\n        String ddlTable = &quot;create table if not exists default.tab_1\\n&quot; +\n                &quot;(\\n&quot; +\n                &quot;    col_1                 string,\\n&quot; +\n                &quot;    col_2                 string,\\n&quot; +\n                &quot;    col_3                 string,\\n&quot; +\n                &quot;    col_4                 string\\n&quot; +\n                &quot;)\\n&quot; +\n                &quot;partitioned by (dt STRING, hr STRING)\\n&quot; +\n                &quot;stored as textfile\\n&quot; +\n                &quot;tblproperties (\\n&quot; +\n                &quot;    'sink.partition-commit.trigger' = 'partition-time',\\n&quot; +\n                &quot;    'sink.partition-commit.delay' = '1 min',\\n&quot; +\n                &quot;    'sink.partition-commit.policy.kind' = 'metastore,success-file',\\n&quot; +\n                &quot;    'partition.time-extractor.timestamp-pattern' = '$dt $hr:00:00'\\n&quot; +\n                &quot;);&quot;;\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        StreamTableEnvironment tEnv = StreamTableEnvironment.create(env);\n\n        tEnv.executeSql(createCatalog);\n        tEnv.executeSql(useCatalog);\n        tEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n        tEnv.executeSql(ddlTable);\n    }\n}\n</code></pre>\n<p>HiveParserFactory exists in META-INF/service/org.apache.flink.table.factories.Factory in my JAR file.\nWhy i get this error?</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}