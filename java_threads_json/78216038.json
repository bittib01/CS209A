{
  "question": {
    "tags": [
      "python",
      "java",
      "apache-spark",
      "pyspark"
    ],
    "owner": {
      "account_id": 30958946,
      "reputation": 11,
      "user_id": 23774552,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/fca654498bca430fbd32e34c4296564a?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Uche Kalu",
      "link": "https://stackoverflow.com/users/23774552/uche-kalu"
    },
    "is_answered": false,
    "view_count": 696,
    "answer_count": 1,
    "score": 0,
    "last_activity_date": 1716536935,
    "creation_date": 1711312970,
    "last_edit_date": 1711361310,
    "question_id": 78216038,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/78216038/i-created-a-dataframe-using-pyspark-but-cannot-view-the-data-created",
    "title": "I created a dataframe using pyspark but cannot view the data created",
    "body": "<p>I created a dataframe using pyspark but cannot view the data created using <code>.show()</code> I'll get the following error:</p>\n<pre><code>Py4JJavaError                             Traceback (most recent call last)\nc:\\Users\\user\\Documents\\Python Programming\\PySpark_for_Big_Data.ipynb Cell 20 line 1\n----&gt; 1 ds.show()\n\nFile C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:945, in DataFrame.show(self, n, truncate, vertical)\n    885 def show(self, n: int = 20, truncate: Union[bool, int] = True, vertical: bool = False) -&gt; None:\n    886     &quot;&quot;&quot;Prints the first ``n`` rows to the console.\n    887 \n    888     .. versionadded:: 1.3.0\n   (...)\n    943     name | Bob\n    944     &quot;&quot;&quot;\n--&gt; 945     print(self._show_string(n, truncate, vertical))\n\nFile C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:963, in DataFrame._show_string(self, n, truncate, vertical)\n    957     raise PySparkTypeError(\n    958         error_class=&quot;NOT_BOOL&quot;,\n    959         message_parameters={&quot;arg_name&quot;: &quot;vertical&quot;, &quot;arg_type&quot;: type(vertical).__name__},\n    960     )\n    962 if isinstance(truncate, bool) and truncate:\n--&gt; 963     return self._jdf.showString(n, 20, vertical)\n    964 else:\n    965     try:\n...\nCaused by: java.io.EOFException\n    at java.base/java.io.DataInputStream.readInt(DataInputStream.java:386)\n    at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:774)\n    ... 26 more\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n</code></pre>\n<p>In my Local Disk, spark folder contains a <code>spark-3.5.1-bin-hadoop3</code> folder which is the spark version.<br />\nI also used <code>pip install pyspark</code> to install pyspark in terminal</p>\n<p>My Environment Variables settings are:<br />\nHADOOP_HOME: <code>C:\\hadoop</code> which contains a <code>winutils</code> file version 3</p>\n<p>SPARK_HOME: <code>C:\\spark\\spark-3.5.1-bin-hadoop3</code></p>\n<p>JAVA_HOME: <code>C:\\Program Files\\Java\\jdk-20</code></p>\n<p>SPARK_LOCAL_IP: <code>127.0.0.1</code></p>\n<p>PYTHONPATH: <code>%SPARK_HOME%\\python;%SPARK_HOME%\\python\\lib\\py4j-0.10.9.7-src.zip</code></p>\n<p>PATH: <code>%HADOOP_HOME%\\bin</code><br />\n<code>%SPARK_HOME%\\bin</code></p>\n<p>Software versions are:<br />\nMy Java Version: <code>java 20.0.2 2023-07-18</code></p>\n<p>My Python version: <code>Python 3.12.0</code></p>\n<p>My Spark version: <code>Spark 3.5.1</code></p>\n<p>Python Kernel used in VS Code IDE: <code>%USERPROFILE%\\AppData\\Local\\Programs\\Python\\Python312\\python.exe</code></p>\n<p>Please advise. I am desperate.</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}