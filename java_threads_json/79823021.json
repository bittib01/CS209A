{
  "question": {
    "tags": [
      "java",
      "pdf"
    ],
    "owner": {
      "account_id": 44716661,
      "reputation": 1,
      "user_id": 31898390,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/e213de02aa6055a4e74b549080109dc8?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "user31898390",
      "link": "https://stackoverflow.com/users/31898390/user31898390"
    },
    "is_answered": false,
    "view_count": 66,
    "answer_count": 1,
    "score": 2,
    "last_activity_date": 1763477836,
    "creation_date": 1763445070,
    "question_id": 79823021,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79823021/how-to-reduce-memory-consumption-when-processing-pdfs-with-large-embedded-images",
    "title": "How to reduce memory consumption when processing PDFs with large embedded images using PDFBox?",
    "body": "<p>I'm using Apache PDFBox to process PDFs that contain very large, embedded images (e.g., 6538x6570px = ~163MB when decompressed). The service consumes 290-446MB of memory during conversion, causing performance issues.</p>\n<p>The P<strong>roblem:</strong></p>\n<ul>\n<li><p>PDF file size: 356KB (compressed)</p>\n</li>\n<li><p>Contains 3 embedded images: 6538x6570px (~163MB), 6538x1899px (~47MB), 2535x376px (~3MB)</p>\n</li>\n<li><p>When PDFBox processes these, it decompresses images into memory at full size before I can downscale them</p>\n</li>\n<li><p>Memory peak: 290-446MB for a single-page PDF</p>\n</li>\n</ul>\n<p>Is there a way to downscale embedded images in PDFBox without loading the full image into memory first? Or is there a better approach to handle large, embedded images?</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}