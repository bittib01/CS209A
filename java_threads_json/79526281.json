{
  "question": {
    "tags": [
      "java",
      "apache-spark"
    ],
    "owner": {
      "account_id": 1956083,
      "reputation": 5433,
      "user_id": 1759063,
      "user_type": "registered",
      "accept_rate": 53,
      "profile_image": "https://i.sstatic.net/hJfRp.jpg?s=256",
      "display_name": "Eljah",
      "link": "https://stackoverflow.com/users/1759063/eljah"
    },
    "is_answered": true,
    "view_count": 33,
    "answer_count": 1,
    "score": 0,
    "last_activity_date": 1742581277,
    "creation_date": 1742580024,
    "question_id": 79526281,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79526281/exception-in-thread-main-org-apache-spark-sql-analysisexception-column-times",
    "title": "Exception in thread &quot;main&quot; org.apache.spark.sql.AnalysisException: Column &#39;timestamp&#39; does not exist. Did you mean one of the following? [timestamp,",
    "body": "<p>Spark doesn't find one column while  njust prints it in the schema:</p>\n<pre><code>import org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Row;\nimport org.apache.spark.sql.SparkSession;\nimport org.jfree.chart.ChartPanel;\nimport org.jfree.chart.JFreeChart;\nimport org.jfree.chart.axis.AxisLocation;\nimport org.jfree.chart.axis.LogarithmicAxis;\nimport org.jfree.chart.axis.NumberAxis;\nimport org.jfree.chart.axis.NumberTickUnit;\nimport org.jfree.chart.labels.StandardXYToolTipGenerator;\nimport org.jfree.chart.plot.XYPlot;\nimport org.jfree.chart.renderer.PaintScale;\nimport org.jfree.chart.renderer.xy.XYBlockRenderer;\nimport org.jfree.chart.title.PaintScaleLegend;\nimport org.jfree.chart.ui.RectangleEdge;\nimport org.jfree.chart.ui.RectangleInsets;\nimport org.jfree.data.xy.DefaultXYZDataset;\nimport org.jfree.data.xy.XYZDataset;\n\nimport javax.imageio.ImageIO;\nimport javax.swing.*;\nimport java.awt.*;\nimport java.io.File;\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.*;\n\nimport static org.apache.spark.sql.functions.*;\n\npublic class GraphDrawer3 {\n    public static void main(String[] args) {\n        SparkSession spark = SparkSession.builder()\n                .appName(&quot;Graph Drawer&quot;)\n                .master(&quot;local[*]&quot;)\n                .getOrCreate();\n\n        String logFilePath = &quot;D:\\\\filtered_logs_with_useragent&quot;;\n        Dataset&lt;Row&gt; logs = spark.read()\n                .option(&quot;delimiter&quot;, &quot;\\t&quot;)\n                .option(&quot;header&quot;, &quot;true&quot;)\n                .csv(logFilePath);\n\n// Checking coulmn name\n        logs.printSchema();\n        logs.show(5, false);\n\n        logs = logs//.\n                 //withColumn(&quot;timestamp_long&quot;, col(&quot;timestamp&quot;).cast(&quot;long&quot;)) \n                .withColumn(&quot;event_time&quot;, from_unixtime(col(&quot;timestamp&quot;))) //&lt;-- fail here\n                .withColumn(&quot;time_window&quot;, unix_timestamp(window(col(&quot;event_time&quot;), &quot;1 minutes&quot;).getField(&quot;start&quot;)))\n                .withColumn(&quot;duration&quot;, col(&quot;duration&quot;).cast(&quot;double&quot;))\n                .withColumn(&quot;out_bytes&quot;, col(&quot;out_bytes&quot;).cast(&quot;double&quot;))\n                .na().fill(0, new String[]{&quot;duration&quot;})\n                .withColumn(&quot;duration_bucket&quot;, floor(col(&quot;out_bytes&quot;).divide(1000)).multiply(1000));\n\n        Dataset&lt;Row&gt; graphData = logs\n                .groupBy(&quot;time_window&quot;, &quot;duration_bucket&quot;)\n                .agg(count(&quot;*&quot;).alias(&quot;request_count&quot;))\n                .orderBy(&quot;time_window&quot;, &quot;duration_bucket&quot;);\n\n        long count = graphData.count();\n        if (count == 0) {\n            System.out.println(&quot;‚ùå No data!&quot;);\n            return;\n        }\n\n        graphData.show(50, false);\n\n        DefaultXYZDataset dataset = new DefaultXYZDataset();\n        double[] xValues, yValues, zValues;\n        double maxRequests;\n\n        Object[] dataArrays = prepareData(graphData);\n        xValues = (double[]) dataArrays[0];\n        yValues = (double[]) dataArrays[1];\n        zValues = (double[]) dataArrays[2];\n        maxRequests = (double) dataArrays[3];\n\n        dataset.addSeries(&quot;Heatmap Data&quot;, new double[][]{xValues, yValues, zValues});\n\n        JFreeChart chart = createChart(dataset, xValues, yValues, maxRequests);\n        displayChart(chart);\n        saveChartAsPNG(chart, &quot;D:\\\\output\\\\graph_03_03_2025_dalvik.png&quot;);\n\n        spark.stop();\n    }\n\n    private static Object[] prepareData(Dataset&lt;Row&gt; graphData) {\n        List&lt;Row&gt; rows = graphData.collectAsList();\n\n        Set&lt;Double&gt; uniqueX = new TreeSet&lt;&gt;();\n        Set&lt;Double&gt; uniqueY = new TreeSet&lt;&gt;();\n\n        for (Row row : rows) {\n            uniqueX.add(((Long) row.getAs(&quot;time_window&quot;)).doubleValue());\n            uniqueY.add(((Long) row.getAs(&quot;duration_bucket&quot;)).doubleValue());\n        }\n\n        int xSize = uniqueX.size();\n        int ySize = uniqueY.size();\n        int totalSize = xSize * ySize;\n\n        double[] xvalues = new double[totalSize];\n        double[] yvalues = new double[totalSize];\n        double[] zvalues = new double[totalSize];\n\n        int index = 0;\n        for (double x : uniqueX) {\n            for (double y : uniqueY) {\n                xvalues[index] = x;\n                yvalues[index] = y;\n                zvalues[index] = 0;\n                index++;\n            }\n        }\n\n        for (Row row : rows) {\n            double x = ((Long) row.getAs(&quot;time_window&quot;)).doubleValue();\n            double y = ((Long) row.getAs(&quot;duration_bucket&quot;)).doubleValue();\n            double z = ((Long) row.getAs(&quot;request_count&quot;)).doubleValue();\n\n            int idx = (new ArrayList&lt;&gt;(uniqueX)).indexOf(x) * ySize + (new ArrayList&lt;&gt;(uniqueY)).indexOf(y);\n            zvalues[idx] = z;\n        }\n\n        double maxRequests = Arrays.stream(zvalues).max().orElse(1);\n        return new Object[]{xvalues, yvalues, zvalues, maxRequests};\n    }\n\n    private static JFreeChart createChart(XYZDataset dataset, double[] xValues, double[] yValues, double maxRequests) {\n        NumberAxis xAxis = new NumberAxis(&quot;Timestamp (30-min Windows)&quot;);\n        xAxis.setAutoRangeIncludesZero(false);\n        //xAxis.setDateFormatOverride(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm&quot;));\n\n        NumberAxis yAxis = new NumberAxis(&quot;Duration (sec)&quot;);\n        yAxis.setAutoRangeIncludesZero(false);\n        yAxis.setTickUnit(new NumberTickUnit(10));\n\n        XYPlot plot = new XYPlot(dataset, xAxis, yAxis, null);\n        XYBlockRenderer renderer = new XYBlockRenderer();\n\n        double xMin = Arrays.stream(xValues).min().orElse(0);\n        double xMax = Arrays.stream(xValues).max().orElse(1);\n        double yMin = Arrays.stream(yValues).min().orElse(0);\n        double yMax = Arrays.stream(yValues).max().orElse(1);\n\n        long uniqueXCount = Arrays.stream(xValues).distinct().count();\n        long uniqueYCount = Arrays.stream(yValues).distinct().count();\n\n        double blockWidth = (xMax - xMin) / uniqueXCount;\n        double blockHeight = (yMax - yMin) / uniqueYCount;\n\n        renderer.setBlockWidth(blockWidth);\n        renderer.setBlockHeight(blockHeight);\n        renderer.setDefaultToolTipGenerator(new StandardXYToolTipGenerator());\n        renderer.setPaintScale(new SpectrumPaintScale(1, maxRequests)); \n        plot.setRenderer(renderer);\n        JFreeChart chart = new JFreeChart(&quot;Heatmap: Requests by Time and Duration&quot;,\n                JFreeChart.DEFAULT_TITLE_FONT, plot, false);\n\n        LogarithmicAxis zAxis = new LogarithmicAxis(&quot;Request Count&quot;);\n        zAxis.setAutoRangeIncludesZero(false);\n        zAxis.setAllowNegativesFlag(false); \n        zAxis.setLowerBound(1); \n        zAxis.setUpperBound(maxRequests);\n\n        PaintScaleLegend legend = new PaintScaleLegend(new SpectrumPaintScale(1, maxRequests), zAxis);\n        legend.setSubdivisionCount(128);\n        legend.setAxisLocation(AxisLocation.TOP_OR_RIGHT);\n        legend.setPadding(new RectangleInsets(25, 10, 50, 10));\n        legend.setStripWidth(20);\n        legend.setPosition(RectangleEdge.RIGHT);\n        legend.setBackgroundPaint(Color.WHITE);\n        chart.addSubtitle(legend);\n\n        return chart;\n    }\n\n\n    private static void displayChart(JFreeChart chart) {\n        JFrame frame = new JFrame(&quot;Heatmap Visualization&quot;);\n        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n        ChartPanel chartPanel = new ChartPanel(chart);\n        chartPanel.setPreferredSize(new Dimension(1400, 800));\n        chartPanel.setMouseZoomable(true, false);\n        frame.add(chartPanel);\n        frame.pack();\n        frame.setLocationRelativeTo(null);\n        frame.setVisible(true);\n    }\n\n    private static void saveChartAsPNG(JFreeChart chart, String filePath) {\n        try {\n            File file = new File(filePath);\n            ImageIO.write(chart.createBufferedImage(1200, 600), &quot;png&quot;, file);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static class SpectrumPaintScale implements PaintScale {\n        private static final float H1 = 0.7f;  \n        private static final float H2 = 0.0f;  \n        private final double lowerBound;\n        private final double upperBound;\n        private final double logLower;\n        private final double logUpper;\n\n        public SpectrumPaintScale(double lowerBound, double upperBound) {\n            this.lowerBound = lowerBound;\n            this.upperBound = upperBound;\n\n            this.logLower = Math.log10(Math.max(lowerBound, 1));\n            this.logUpper = Math.log10(Math.max(upperBound, 1));\n        }\n\n        @Override\n        public double getLowerBound() {\n            return lowerBound;\n        }\n\n        @Override\n        public double getUpperBound() {\n            return upperBound;\n        }\n\n        @Override\n        public Paint getPaint(double value) {\n            if (value &lt;= lowerBound) {\n                return Color.getHSBColor(H1, 1f, 1f); \n            }\n            if (value &gt;= upperBound) {\n                return Color.getHSBColor(H2, 1f, 1f); \n            }\n\n            double logValue = Math.log10(Math.max(value, 1));\n            float scaledValue = (float) ((logValue - logLower) / (logUpper - logLower));\n\n            float scaledH = H1 + scaledValue * (H2 - H1);\n            return Color.getHSBColor(scaledH, 1f, 1f);\n        }\n    }\n}\n</code></pre>\n<p>and that was the output to the logs before the fail:</p>\n<pre><code>25/03/21 14:14:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 79). 2007 bytes result sent to driver\n25/03/21 14:14:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 79) in 32 ms on ILYA.mshome.net (executor driver) (1/1)\n25/03/21 14:14:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n25/03/21 14:14:46 INFO DAGScheduler: ResultStage 2 (show at GraphDrawer3.java:52) finished in 0.042 s\n25/03/21 14:14:46 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n25/03/21 14:14:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n25/03/21 14:14:46 INFO DAGScheduler: Job 2 finished: show at GraphDrawer3.java:52, took 0.045052 s\n25/03/21 14:14:46 INFO CodeGenerator: Code generated in 9.4934 ms\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|timestamp,remote_addr,remote_user,time_local,request,status,body_bytes_sent,out_bytes,referrer,useragent,http_x_forwarded_for,host,torso_id,duration,upstream_response_time,upstream_status,country,service,cache_status,logtype,custom_field                                                    |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|1741031986.377,185.41.120.58,-,2025-03-03 19:59:46+0000,GET /aa/7907728753176af1c64284d1c873a838a4a93b071.jpg?w=300 HTTP/1.1,200,25713,26186,-,Dalvik/2.1.0 (Linux; U; Android 14; 23090RA98G Build/UP1A.231005.007),-,cache-limeshop.cdnvideo.ru,468,0,-,-,RU,static,HIT,n_c,          |\n|1741031986.404,185.41.120.58,-,2025-03-03 19:59:46+0000,GET /aa/79077289012d0f384d3e14982adfcd7286073cfa9.jpg?w=300 HTTP/1.1,200,30450,30923,-,Dalvik/2.1.0 (Linux; U; Android 14; 23090RA98G Build/UP1A.231005.007),-,cache-limeshop.cdnvideo.ru,468,0,-,-,RU,static,HIT,n_c,          |\n|1741031986.418,185.41.120.58,-,2025-03-03 19:59:46+0000,GET /aa/7907728753176af1c64284d1c873a838a4a93b071.jpg?w=534 HTTP/1.1,200,31499,31973,-,Dalvik/2.1.0 (Linux; U; Android 14; 23090RA98G Build/UP1A.231005.007),-,cache-limeshop.cdnvideo.ru,468,0.004,0.004,200,RU,static,HIT,n_c,|\n|1741031986.663,185.41.120.58,-,2025-03-03 19:59:46+0000,GET /aa/792693224cbf7cacd86b0408285b116b674fb674d.jpg?w=300 HTTP/1.1,200,45336,45809,-,Dalvik/2.1.0 (Linux; U; Android 14; 23090RA98G Build/UP1A.231005.007),-,cache-limeshop.cdnvideo.ru,468,0,-,-,RU,static,HIT,n_c,          |\n|1741031986.787,185.41.120.58,-,2025-03-03 19:59:46+0000,GET /aa/79163443747900bf957fd420fa10b1b447010b4a5.jpg?w=598 HTTP/1.1,200,59851,60325,-,Dalvik/2.1.0 (Linux; U; Android 14; 23090RA98G Build/UP1A.231005.007),-,cache-limeshop.cdnvideo.ru,468,0.004,0.004,200,RU,static,HIT,n_c,|\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\nException in thread &quot;main&quot; org.apache.spark.sql.AnalysisException: Column 'timestamp' does not exist. Did you mean one of the following? [timestamp,remote_addr,remote_user,time_local,request,status,body_bytes_sent,out_bytes,referrer,useragent,http_x_forwarded_for,host,torso_id,duration,upstream_response_time,upstream_status,country,service,cache_status,logtype,custom_field];\n'Project [timestamp,remote_addr,remote_user,time_local,request,status,body_bytes_sent,out_bytes,referrer,useragent,http_x_forwarded_for,host,torso_id,duration,upstream_response_time,upstream_status,country,service,cache_status,logtype,custom_field#17, from_unixtime('timestamp, yyyy-MM-dd HH:mm:ss, Some(Europe/Moscow)) AS event_time#26]\n+- Relation [timestamp,remote_addr,remote_user,time_local,request,status,body_bytes_sent,out_bytes,referrer,useragent,http_x_forwarded_for,host,torso_id,duration,upstream_response_time,upstream_status,country,service,cache_status,logtype,custom_field#17] csv\n\n    at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:54)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$7(CheckAnalysis.scala:200)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$7$adapted(CheckAnalysis.scala:193)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    at scala.collection.Iterator.foreach(Iterator.scala:943)\n    at scala.collection.Iterator.foreach$(Iterator.scala:943)\n    at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    at scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    at scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    at scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:366)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:366)\n    at scala.collection.Iterator.foreach(Iterator.scala:943)\n    at scala.collection.Iterator.foreach$(Iterator.scala:943)\n    at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    at scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    at scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    at scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:366)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$6(CheckAnalysis.scala:193)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$6$adapted(CheckAnalysis.scala:193)\n    at scala.collection.immutable.Stream.foreach(Stream.scala:533)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:193)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:102)\n    at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:367)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:102)\n    at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:97)\n    at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:187)\n    at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:210)\n    at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n    at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:207)\n    at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\n    at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n    at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\n    at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n    at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\n    at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\n    at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\n    at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n    at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n    at org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:91)\n    at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n    at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:89)\n    at org.apache.spark.sql.Dataset.withPlan(Dataset.scala:3887)\n    at org.apache.spark.sql.Dataset.select(Dataset.scala:1519)\n    at org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2542)\n    at org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2480)\n    at cdnloganalysis.GraphDrawer3.main(GraphDrawer3.java:57)\n</code></pre>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}