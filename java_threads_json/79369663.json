{
  "question": {
    "tags": [
      "java",
      "apache-spark",
      "amazon-s3"
    ],
    "owner": {
      "account_id": 10859209,
      "reputation": 19,
      "user_id": 7984557,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/e3a53ab19bba3031914c8e111f6b6e30?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "shi",
      "link": "https://stackoverflow.com/users/7984557/shi"
    },
    "is_answered": false,
    "view_count": 170,
    "answer_count": 2,
    "score": 0,
    "last_activity_date": 1738642242,
    "creation_date": 1737316461,
    "last_edit_date": 1737336411,
    "question_id": 79369663,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79369663/unable-to-authenticate-s3-with-s3a-pyspark-config-i-want-to-get-the-code-to-wor",
    "title": "Unable to authenticate S3 with S3A pyspark config. I want to get the code to work in EMR hence, avoiding the temporal credentials for 1 hour",
    "body": "<pre><code>Error: org.apache.hadoop.fs.s3a.auth.NoAuthWithAWSException: No AWS Credentials provided by TemporaryAWSCredentialsProvider SimpleAWSCredentialsProvider EnvironmentVariableCredentialsProvider IAMInstanceCredentialsProvider : com.amazonaws.SdkClientException: Unable to load AWS credentials from environment variables (AWS_ACCESS_KEY_ID (or AWS_ACCESS_KEY) and AWS_SECRET_KEY (or AWS_SECRET_ACCESS_KEY))\n</code></pre>\n<pre><code>                                 &quot;com.amazonaws.auth.profile.DefaultAWSCredentialsProviderChain&quot;)\n                        .config(&quot;spark.hadoop.fs.s3a.access.key&quot;,\n                                AWSHandler.get_session(Constant.aws_sso_profile).get_credentials().access_key)\n                        .config(&quot;spark.hadoop.fs.s3a.secret.key&quot;,\n                                AWSHandler.get_session(Constant.aws_sso_profile).get_credentials().secret_key)\n                         .config(&quot;spark.hadoop.fs.s3a.impl&quot;, &quot;org.apache.hadoop.fs.s3a.S3AFileSystem&quot;)\n                         .config('spark.executor.instances', 4).getOrCreate()\n                         )\n                return spark\n</code></pre>\n<p>In production, hard coding the access and secret key is not allowed which leaves me with either this apporach of getting the access from .aws</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}