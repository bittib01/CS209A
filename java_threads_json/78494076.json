{
  "question": {
    "tags": [
      "java",
      "matrix",
      "neural-network",
      "gradient-descent",
      "image-classification"
    ],
    "owner": {
      "account_id": 32311394,
      "reputation": 11,
      "user_id": 25094293,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/fe2472ac556b0be0b442186cc628aa2a?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Mark Agib",
      "link": "https://stackoverflow.com/users/25094293/mark-agib"
    },
    "is_answered": false,
    "view_count": 56,
    "answer_count": 0,
    "score": 1,
    "last_activity_date": 1755422881,
    "creation_date": 1715930283,
    "last_edit_date": 1755422881,
    "question_id": 78494076,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/78494076/mnist-image-classification-gradient-descent-neural-network-not-working",
    "title": "MNIST Image Classification Gradient Descent Neural Network not working",
    "body": "<p>I have to files PreProcess.java:</p>\n<pre class=\"lang-java prettyprint-override\"><code>/*\n * 4/28/24\n * Final\n */\n\npackage Final;\n\nimport java.io.DataInputStream;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\n\n/*\n * To DO\n * Add labels to program\n * One hot encode labels\n * xavier insantztion \n */\n\npublic class PreProcess {\n    public static double[][] processImages(int numImagesToRead) throws FileNotFoundException, IOException {\n        String filePath = &quot;C:\\\\Users\\\\Mark\\\\APCSA\\\\Final\\\\samples\\\\train-images.idx3-ubyte&quot;;\n    \n        try (DataInputStream inputStream = new DataInputStream(new FileInputStream(filePath))) {\n            int magicNumber = inputStream.readInt();\n            if (magicNumber != 0x00000803) {\n                System.err.println(&quot;Invalid magic number. This may not be a valid image file.&quot;);\n                return null;\n            }\n    \n            int numImages = inputStream.readInt();\n            int numRows = inputStream.readInt();\n            int numColumns = inputStream.readInt();\n            System.out.println(&quot;Processing &quot; + numImagesToRead + &quot; &quot; + numRows + &quot;x&quot; + numColumns + &quot; images&quot;);\n    \n            byte[][][] images = new byte[numImages][numRows][numColumns];\n            for (int i = 0; i &lt; numImagesToRead; i++) { // Changed loop condition\n                for (int row = 0; row &lt; numRows; row++) {\n                    for (int col = 0; col &lt; numColumns; col++) {\n                        images[i][row][col] = inputStream.readByte();\n                    }\n                }\n                if (i % 10 == 0) {\n                    updateProgress(i, numImagesToRead);\n                }\n            }\n    \n            double[][] orderedImages = new double[numImagesToRead][numRows * numColumns]; // Changed to numImagesToRead\n            for (int i = 0; i &lt; numImagesToRead; i++) {\n                orderedImages[i] = minMaxNormalization(flaten(images[i], numRows, numColumns));\n            }\n            System.out.println(&quot;&quot;);\n            System.out.println(&quot;Finished processing images!&quot;);\n            return transpose(orderedImages);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n    \n\n    public static double[][] processLabels(int numLabelsToRead) {\n        String labelFilePath = &quot;C:\\\\Users\\\\Mark\\\\APCSA\\\\Final\\\\samples\\\\train-labels.idx1-ubyte&quot;;\n        try (DataInputStream inputStream = new DataInputStream(new FileInputStream(labelFilePath))) {\n            int magicNumber = inputStream.readInt();\n            if (magicNumber != 0x00000801) {\n                System.err.println(&quot;Invalid magic number. This may not be a valid labels file.&quot;);\n                return null;\n            }\n\n            int numLabels = numLabelsToRead;\n            byte[] labels = new byte[numLabels];\n            inputStream.read(labels);\n\n            System.out.println(&quot;Processing &quot; + numLabels + &quot; labels&quot;);\n\n            double[] orderedLabels = new double[numLabels];\n            for (int i = 0; i &lt; numLabels; i++) {\n                orderedLabels[i] = labels[i];\n            }\n            double[] categories = {0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0};\n\n            System.out.println(&quot;Finiished processing labels!&quot;);\n            return oneHotEncode(orderedLabels, categories);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n\n    public static byte[] flaten(byte[][] image, int numRows, int numColumns) {\n        byte[] temp = new byte[numColumns * numRows];\n\n        int i = 0;\n        for (int row = 0; row &lt; numRows; row++) {\n            for (int col = 0; col &lt; numColumns; col++) {\n                temp[i] = image[row][col];\n                i++;\n            }\n        }    \n        return temp;\n    }\n\n    public static double[] minMaxNormalization(byte[] image) {\n        byte minPixelValue = Byte.MAX_VALUE;\n        byte maxPixelValue = Byte.MIN_VALUE;\n        for (byte pixelValue : image) {\n            if (pixelValue &lt; minPixelValue) {\n                minPixelValue = pixelValue;\n            }\n            if (pixelValue &gt; maxPixelValue) {\n                maxPixelValue = pixelValue;\n            }\n        }\n\n        double[] newImages = new double[image.length];\n\n        for (int i = 0; i &lt; image.length; i++) {\n            newImages[i] = ((image[i]- minPixelValue)/(maxPixelValue - minPixelValue));\n        }\n\n        return newImages;\n    }\n\n    public static double[][] transpose(double[][] array) {\n        int length = array.length;\n        int imageSize = array[0].length;\n        double[][] transposedMatrix = new double[imageSize][length];\n\n        for (int i = 0; i &lt; imageSize; i++) {\n            for (int j = 0; j &lt; length; j++) {\n                transposedMatrix[i][j] = array[j][i];\n            }\n        }\n\n        return transposedMatrix;\n    }\n    \n    public static double[][] oneHotEncode(double[] labels, double[] categories) {\n        double[][] result = new double[categories.length][labels.length];\n\n        for (int i = 0; i &lt; categories.length; i++) {\n            for (int j = 0; j &lt; labels.length; j++) {\n                if (labels[j] == categories[i]) {\n                    result[i][j] = 1.0;\n                }\n            }\n        }\n\n        return result;\n    }\n\n\n    public static void updateProgress(int currentStep, int totalSteps) {\n        double progress = (double) currentStep / totalSteps;\n        int barLength = 100;\n\n        System.out.print(&quot;\\r[&quot;);\n        int progressChars = (int) (progress * barLength);\n        for (int i = 0; i &lt; barLength; i++) {\n            if (i &lt; progressChars) {\n                System.out.print(&quot;=&quot;);\n            } else {\n                System.out.print(&quot; &quot;);\n            }\n        }\n        System.out.printf(&quot;] %.2f%%&quot;, progress * 100);\n    }\n\n    // public static void accuracy() {\n    // }\n\n    public static double[][] dot(double[][] matrixA, double[][] matrixB) {\n        double[][] newMatrix = new double[matrixA.length][matrixB[0].length];\n\n        for (int i = 0; i &lt; newMatrix.length; i++) {\n            for (int j = 0; j &lt; newMatrix[i].length; j++) {\n                for (int k = 0; k &lt; matrixB.length; k++) {\n                    newMatrix[i][j] += matrixA[i][k] * matrixB[k][j];\n                }\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double[][] matrixCoefficientMultiplication(double[][] matrix, double coefficent) {\n        double[][] newMatrix = new double[matrix.length][matrix[0].length];\n\n        for (int i = 0; i &lt; newMatrix.length; i++) {\n            for (int j = 0; j &lt; newMatrix[i].length; j++) {\n                newMatrix[i][j] = matrix[i][j] * coefficent;\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double[][] matrixOperations(double[][] matrixA, double[][] matrixB, boolean subtraction) {\n        double[][] newMatrix = new double[matrixA.length][matrixA[0].length];\n\n        double[][] newMatrixB;\n        if (subtraction) {\n            newMatrixB = matrixCoefficientMultiplication(matrixB, -1.0);\n        }\n        else {\n            newMatrixB = matrixB;\n        }\n        \n        for (int i = 0; i &lt; newMatrix.length; i++) {\n            for (int j = 0; j &lt; newMatrix[i].length; j++) {\n                newMatrix[i][j] = matrixA[i][j] + newMatrixB[i][j];\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double[][] matrixExp(double[][] matrix) {\n        double[][] newMatrix = new double[matrix.length][matrix[0].length];\n\n        for (int i = 0; i &lt; newMatrix.length; i++) {\n            for (int j = 0; j &lt; newMatrix[i].length; j++) {\n                newMatrix[i][j] = Math.exp(matrix[i][j]);\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double sum(double[][] matrix) {\n        double sum = 0;\n        \n        for (int i = 0; i &lt; matrix.length; i++) {\n            for (int j = 0; j &lt; matrix[i].length; j++) {\n                sum += matrix[i][j];\n            }\n        }\n\n        return sum;\n    }\n\n    public static double[][] sumSecondAxis(double[][] array) {\n        double[][] sums = new double[array.length][1];\n\n        for (int i = 0; i &lt; array.length; i++) {\n            double sum = 0.0;\n            for (int j = 0; j &lt; array[i].length; j++) {\n                sum += array[i][j];\n            }\n            sums[i][0] = sum;\n        }\n\n        return sums;\n    }\n\n    public static double[][] reshape(double[][] matrix) {\n        double[][] newMatrix = new double[matrix.length * matrix[0].length][1];\n\n        int k = 0;\n        for (int i = 0; i &lt; matrix.length; i++) {\n            for (int j = 0; j &lt; matrix[i].length; j++) {\n                newMatrix[k][0] = matrix[i][j];\n                k++;\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double[] reshape(double[][] matrix, int numColumns) {\n        double[] newMatrix = new double[matrix.length * matrix[0].length];\n\n        int k = 0;\n        for (int i = 0; i &lt; matrix.length; i++) {\n            for (int j = 0; j &lt; matrix[i].length; j++) {\n                newMatrix[k] = matrix[i][j];\n                k++;\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double[][] copyAcross(double[][] matrix, int numColumns) {\n        double[][] result = new double[matrix.length][numColumns];\n\n        for (int i = 0; i &lt; matrix.length; i++) {\n            double value = matrix[i][0]; \n            for (int j = 0; j &lt; numColumns; j++) {\n                result[i][j] = value;\n            }\n        }\n\n        return result;\n    }\n}\n\n\n</code></pre>\n<p>And Main.java in a folder called Final:</p>\n<pre class=\"lang-java prettyprint-override\"><code>package Final;\n\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.util.Random;\nimport java.util.Scanner;\n\nclass ActivationFunction {\n    // possibly swith to rmsprop for better op\n    public static double sigmoid(double x) {\n        return 1 / (1 + Math.exp(-x));\n    }\n\n    public static double sigmoidDerivative(double x) {\n        return sigmoid(x) * (1 - sigmoid(x));\n    }\n\n    public static double[][] rectifiedLinearUnit(double[][] matrix) {\n        double[][] newMatrix = new double[matrix.length][matrix[0].length];\n\n        for (int i = 0; i &lt; newMatrix.length; i++) {\n            for (int j = 0; j &lt; newMatrix[i].length; j++) {\n                if (matrix[i][j] &lt;= 0.0) {\n                    newMatrix[i][j] = 0.0;\n                }\n                else {\n                    newMatrix[i][j] = 1.0;\n                }\n            }\n        }\n\n        return newMatrix;\n    }\n\n    public static double[][] deravtiveRectifiedLinearUnit(double[][] matrix) {\n        double[][] derivative = new double[matrix.length][matrix[0].length];\n        \n        for (int i = 0; i &lt; matrix.length; i++) {\n            for (int j = 0; j &lt; matrix[i].length; j++) {\n                if (matrix[i][j] &lt;= 0) {\n                    derivative[i][j] = 0;\n                } else {\n                    derivative[i][j] = 1;\n                }\n            }\n        }\n        \n        return derivative;\n    }\n    \n    \n    public static double[][] softMax(double[][] matrix) {\n        double[][] softmax = new double[matrix.length][matrix[0].length];\n        \n        for (int i = 0; i &lt; matrix.length; i++) {\n            double sum = 0;\n            for (int j = 0; j &lt; matrix[i].length; j++) {\n                sum += Math.exp(matrix[i][j]);\n            }\n            for (int j = 0; j &lt; matrix[i].length; j++) {\n                softmax[i][j] = Math.exp(matrix[i][j]) / sum;\n            }\n        }\n        \n        return softmax;\n    }    \n}\n\nclass Neuron {\n    private double[] weights;\n    private double bias;\n\n    public Neuron(int numInputs, int numOutputs) {\n        Random rand = new Random();\n        double initWeightRange = Math.sqrt(6.0 / (numInputs + numOutputs)); // Xavier initialization\n        weights = new double[numInputs];\n        for (int i = 0; i &lt; numInputs; i++) {\n            weights[i] = rand.nextDouble() * 2 * initWeightRange - initWeightRange;\n        }\n        bias = 0.0; // Initialize bias to zero\n    }\n\n    public double[] getWeights() {\n        return weights;\n    }\n\n    public double getBias() {\n        return bias;\n    }\n\n    public void updateWeights(double[] weights) {\n        this.weights = weights;\n    }\n\n    public void updateBias(double bias) {\n        this.bias = bias;\n    }\n}\n\nclass Layer {\n    private Neuron[] neurons;\n\n    public Layer(int numNeurons, int numInputsPerNeuron, int numOutputNeurons) {\n        neurons = new Neuron[numNeurons];\n        for (int i = 0; i &lt; numNeurons; i++) {\n            neurons[i] = new Neuron(numInputsPerNeuron, numOutputNeurons);\n        }\n    }\n\n    // public double[][] calculateOutputs(double[] inputs, int numberOfImages) {\n    //     double[][] outputs = new double[numberOfImages][neurons.length];\n\n    //     for (int r = 0; r &lt; neurons.length; r++) {\n    //         for (int c = 0; c &lt; neurons.length; c++) {\n    //             outputs[r][c] = neurons[c].calculateOutput(inputs);\n    //         }\n    //     }\n        \n    //     return outputs;\n    // }\n\n    // public double[] calculateOutputs(double[] inputs, double[] target) {\n    //     double[] classProb = new double[inputs.length];\n    //     for (int i = 0; i &lt; inputs.length; i++) {\n    //         classProb[i] = ActivationFunction.softMax(inputs[i], inputs);\n    //     }\n    //     return classProb;\n    // }\n\n    public static int classify(double[] classProb) {\n        double highest = classProb[0];\n        int highestIndex = 0;\n\n        for (int j = 0; j &lt; classProb.length; j++) {\n            if (highest &lt; classProb[j]) {\n                highest = classProb[j];\n                highestIndex = j;\n            }\n        }\n        \n        return highestIndex;\n    }\n\n    public Neuron[] getNeurons() {\n        return neurons;\n    }\n\n    public void updateNeurons(double[][] weights, double[] bias) {\n        for (int i = 0; i &lt; neurons.length; i++) {\n            neurons[i].updateWeights(weights[i]);\n            neurons[i].updateBias(bias[i]);\n        }\n    }\n}\n\nclass NeuralNetwork {\n    private Layer hiddenLayer;\n    private Layer outputLayer;\n\n    public NeuralNetwork(int numInputNeurons, int numHiddenNeurons, int numOutputNeurons) {\n        hiddenLayer = new Layer(numHiddenNeurons, numInputNeurons, numOutputNeurons);\n        outputLayer = new Layer(numOutputNeurons, numHiddenNeurons, numOutputNeurons);\n    }\n\n    // public double[] forwardPass(double[] inputs) {\n    //     double[] hiddenOutputs = hiddenLayer.calculateOutputs(inputs);\n    //     return outputLayer.calculateOutputs(hiddenOutputs); //fix\n    // }\n\n    public int[] getPredctions(double[][] percentageMatrix) {\n        int[] predictions = new int[percentageMatrix[0].length];\n        double[][] tempMatrix = PreProcess.transpose(percentageMatrix);\n\n        for (int i = 0; i &lt; tempMatrix.length; i++) {\n            double highest = tempMatrix[i][0];\n            int highestIndex = 0;\n\n            for (int j = 0; j &lt; tempMatrix[i].length; j++) {\n                if (tempMatrix[i][j] &gt; highest) {\n                    highest = tempMatrix[i][j];\n                    highestIndex = j;\n                }\n            }\n\n            predictions[i] = highestIndex;\n        }\n        \n        return predictions;\n    }\n\n    public double train(double[][] inputs, double[][] targets, double learningRate, int numberOfImages, int epoch) {\n        double[][] hiddenWeights = new double[targets.length][inputs.length];\n        double[][] hiddenBiases = new double[targets.length][1];\n        Neuron[] hiddenNeurons = hiddenLayer.getNeurons();\n        for (int i = 0; i &lt; hiddenNeurons.length; i++) {\n            hiddenWeights[i] = hiddenNeurons[i].getWeights();\n            hiddenBiases[i][0] = hiddenNeurons[i].getBias();\n        }\n        \n        double[][] hiddenInputs = PreProcess.matrixOperations(PreProcess.dot(hiddenWeights, inputs), PreProcess.copyAcross(hiddenBiases, numberOfImages), false);\n        double[][] hiddenOutputs = ActivationFunction.rectifiedLinearUnit(hiddenInputs);\n\n        double[][] outputWeights = new double[targets.length][inputs.length];\n        double[][] outputBiases = new double[targets.length][1];\n        Neuron[] outputNeurons = outputLayer.getNeurons();\n        for (int i = 0; i &lt; outputNeurons.length; i++) {\n            outputWeights[i] = outputNeurons[i].getWeights();\n            outputBiases[i][0] = outputNeurons[i].getBias();\n        }\n\n        double[][] outputInputs = PreProcess.matrixOperations(PreProcess.dot(outputWeights, hiddenOutputs), PreProcess.copyAcross(outputBiases, numberOfImages), false);\n        double[][] actualOutputs = ActivationFunction.softMax(outputInputs);\n\n        // back prob down here\n\n        double[][] outputErrors = PreProcess.matrixCoefficientMultiplication(PreProcess.matrixOperations(actualOutputs, targets, true), 2);\n        \n        double[][] deravtiveOutputWeigths = PreProcess.matrixCoefficientMultiplication(PreProcess.dot(outputErrors, PreProcess.transpose(hiddenOutputs)), (1.0 / numberOfImages));\n        double[][] deravtiveOutputBiases = PreProcess.matrixCoefficientMultiplication(PreProcess.sumSecondAxis(outputErrors), (1.0 / numberOfImages));\n\n        double[][] hiddenErrors = PreProcess.dot(PreProcess.dot(PreProcess.transpose(deravtiveOutputWeigths), outputErrors), ActivationFunction.deravtiveRectifiedLinearUnit(hiddenInputs));\n\n        double[][] deravtiveHiddenWeigths = PreProcess.matrixCoefficientMultiplication(PreProcess.dot(hiddenErrors, PreProcess.transpose(inputs)), (1.0 / numberOfImages));\n        double[][] deravtiveHiddenBiases = PreProcess.matrixCoefficientMultiplication(PreProcess.sumSecondAxis(hiddenErrors), (1.0 / numberOfImages));\n\n        // updating time :)\n        outputLayer.updateNeurons(PreProcess.matrixOperations(outputWeights, PreProcess.matrixCoefficientMultiplication(deravtiveOutputWeigths, learningRate), true), PreProcess.reshape(PreProcess.matrixOperations(outputBiases, PreProcess.matrixCoefficientMultiplication(PreProcess.reshape(deravtiveOutputBiases), learningRate), true), 0));\n        hiddenLayer.updateNeurons(PreProcess.matrixOperations(hiddenWeights, PreProcess.matrixCoefficientMultiplication(deravtiveHiddenWeigths, learningRate), true), PreProcess.reshape(PreProcess.matrixOperations(hiddenBiases, PreProcess.matrixCoefficientMultiplication(PreProcess.reshape(deravtiveHiddenBiases), learningRate), true), 0));\n        \n        double sum = 0;\n        if (epoch % 50 == 0) {\n            int[] predictions = getPredctions(actualOutputs);\n            for (int k = 0; k &lt; predictions.length; k++) {\n                if (targets[predictions[k]][k] == 1.0) {\n                    sum += 1;\n                }\n            }\n            \n            return sum / numberOfImages;\n        }\n\n        // double[][] actualOutputs\n        // double[][] hiddenOutputs = hiddenLayer.calculateOutputs(inputs, numberOfImages);\n        // double[] actualOutputs = outputLayer.calculateOutputs(outputLayer.calculateOutputs(hiddenOutputs), targets);\n        // double sum = 0;\n\n        // // all back prob lower\n        // double[] outputErrors = new double[actualOutputs.length];\n        // for (int i = 0; i &lt; actualOutputs.length; i++) {\n        //     outputErrors[i] = actualOutputs[i] - targets[i]; // fix targets use\n        // }\n\n        // if (exampleNumber == 59999) {\n        //     // targets are one hot encoded and I used them diff\n        //     for (int i = 0; i &lt; actualOutputs.length; i++) {\n        //         int correctIndex = 0;\n        //         for (int j = 0; j &lt; targets.length; j++) {\n        //             if (targets[j] == 1.0) {\n        //                 correctIndex = j;\n        //             }\n        //         }\n        //         if (Layer.classify(actualOutputs) == correctIndex) {\n        //             sum += 1;\n        //         }\n        //     }\n\n        //     sum = sum / actualOutputs.length;\n        // }\n        // // above = goog fix below to show changes\n        // // deravtive of weights = (1/number of training images) dZ(output errors) (outputs of output layer)\n        // Neuron[] outputNeurons = outputLayer.getNeurons();\n        // // = new double[outputErrors.length][hiddenOutputs.length]; //(1.0 / outputNeurons.length * hiddenOutputs.length);\n        // double[] deravtiveBiases = new double[outputErrors.length];\n        // final double averageMaker = (1.0 / numberOfImages);\n        //double[][] deravtiveWeigths = PreProcess.matrixCoefficientMultiplication(PreProcess.dot(outputErrors, actualOutputs), averageMaker);\n        //for (int i = 0; i &lt; deravtiveWeigths.length; i++) {\n        //     deravtiveWeigths[i] = outputErrors[i] * actualOutputs[i] * averageMaker;\n        //     double[] outputWeights = outputNeurons[i].getWeights();\n        //     double outputBias = outputNeurons[i].getBias();\n        //     for (int j = 0; j &lt; outputWeights.length; j++) {\n        //         outputWeights[j] += learningRate * outputErrors[i] * ActivationFunction.sigmoidDerivative(outputNeurons[i].getOutput()) * hiddenOutputs[j];\n        //     }\n        //     outputBias += learningRate * outputErrors[i] * ActivationFunction.sigmoidDerivative(outputNeurons[i].getOutput());\n        //}\n        \n\n        // // Update weights and biases in hidden layer\n        // Neuron[] hiddenNeurons = hiddenLayer.getNeurons();\n        // for (int i = 0; i &lt; hiddenNeurons.length; i++) {\n        //     double[] hiddenWeights = hiddenNeurons[i].getWeights();\n        //     double hiddenBias = hiddenNeurons[i].getBias();\n        //     double sum2 = 0;\n        //     for (int j = 0; j &lt; outputNeurons.length; j++) {\n        //         sum2 += outputErrors[j] * ActivationFunction.sigmoidDerivative(outputNeurons[j].getOutput()) * outputNeurons[j].getWeights()[i];\n        //     }\n        //     for (int j = 0; j &lt; hiddenWeights.length; j++) {\n        //         hiddenWeights[j] += learningRate * sum2 * ActivationFunction.sigmoidDerivative(hiddenNeurons[i].getOutput()) * inputs[j];\n        //     }\n        //     hiddenBias += learningRate * sum2 * ActivationFunction.sigmoidDerivative(hiddenNeurons[i].getOutput());\n        // }\n\n        return sum;\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) throws FileNotFoundException, IOException {\n        NeuralNetwork neuralNetwork = new NeuralNetwork(784, 10, 10);\n\n        System.out.println(&quot;[*] Choose an Option below and enter the number:&quot;);\n        System.out.println(&quot;1. Train&quot;);\n        System.out.println(&quot;2. Test&quot;);\n\n        /*\n         * TO DO:\n         * Parallel Processing\n         * using ByteBuffer\n         * Adding print statments to show progess \n         * Allow error checking?\n         * intliaze arrays outside of loops to save mem\n         */\n\n        @SuppressWarnings(&quot;resource&quot;)\n        Scanner input = new Scanner(System.in);\n        int option = input.nextInt();\n        if (option == 1) {\n            double[][] trainingInputs = PreProcess.processImages(2000);\n            double[][] trainingOutputs = PreProcess.processLabels(2000);\n            int epochs = 400;\n            double learningRate = 0.1;\n            System.out.println(&quot;Starting training&quot;);\n            for (int i = 0; i &lt; epochs; i++) {\n                double accuracy = neuralNetwork.train(trainingInputs, trainingOutputs, learningRate, 2000, i);\n                if (i % 50 == 0) {\n                    System.out.println(&quot;Epoch: &quot; + i + &quot; Accuarcy: &quot; + accuracy);\n                }\n            }\n            // for (int i = 0; i &lt; epochs; i++) {\n            //     double accuracy = 0;\n            //     for (int l = 0; l &lt; trainingInputs.length; l++) {\n            //         currentImage = trainingInputs[l];\n            //         currentLabel = trainingOutputs[l];\n            //         accuracy = neuralNetwork.train(currentImage, currentLabel, learningRate, l);\n            //         if (i % 40 == 0){\n            //             PreProcess.updateProgress(l, trainingInputs.length);\n            //         }\n            //     }\n            //     System.out.println(&quot;Epoch: &quot; + i + &quot;Accuracy: &quot; + accuracy);\n            // }\n            // make sure array stuct aligns\n        } else if (option == 2) {\n            /*\n            int correctPredictions = 0;\n                for (int i = 0; i &lt; testDataSize; i++) {\n                    double[] predictedOutputs = neuralNetwork.forwardPass(testInputs[i]);\n                    int predictedLabel = findIndexOfMax(predictedOutputs);\n                    if (predictedLabel == trueLabels[i]) { // Assuming trueLabels contain ground truth labels\n                        correctPredictions++;\n                    }\n                }\n                double accuracy = (double) correctPredictions / testDataSize;\n\n             */\n        } else {\n            System.out.println(&quot;No second Chances try again next time&quot;);\n        }\n\n        // for (int i = 0; i &lt; trainingInputs.length; i++) {\n        //     double[] inputs = trainingInputs[i];\n        //     double[] predictedOutputs = neuralNetwork.forwardPass(inputs);\n        //     System.out.println(&quot;Input: &quot; + inputs[0] + &quot;, &quot; + inputs[1] + &quot; | Predicted Output: &quot; + predictedOutputs[0]);\n        // }\n    }\n}\n</code></pre>\n<p>I followed a python tutorial and this <a href=\"https://www.kaggle.com/code/wwsalmon/simple-mnist-nn-from-scratch-numpy-no-tf-keras/comments#1830757\" rel=\"nofollow noreferrer\">comment</a> but was not able to use it\nMy code produces horrible accuracy Ex:</p>\n<pre><code>Epoch: 0 Accuarcy: 0.1035\nEpoch: 50 Accuarcy: 0.1015\nEpoch: 100 Accuarcy: 0.1025\nEpoch: 150 Accuarcy: 0.1035\nEpoch: 200 Accuarcy: 0.105\nEpoch: 250 Accuarcy: 0.104\nEpoch: 300 Accuarcy: 0.103\nEpoch: 350 Accuarcy: 0.1035\n</code></pre>\n<p>I tried looking everywhere and there are no java implementations of a neural network. Can you please suggest changes or why this may be happening?</p>\n<p>I tried swapping different activation functions and tried implenting cross entropy loss all of which failed miserably. Any help would be greatly appreciated since this is for a final project and before you yell at me I am not willingly choosing to implement this in java.</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}