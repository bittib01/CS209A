{
  "question": {
    "tags": [
      "java",
      "android",
      "firebase",
      "tensorflow",
      "firebase-machine-learning"
    ],
    "owner": {
      "account_id": 35495580,
      "reputation": 13,
      "user_id": 27242445,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/18879d75ac241a04ab7e4cd935cf443e?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Arrgina 2657",
      "link": "https://stackoverflow.com/users/27242445/arrgina-2657"
    },
    "is_answered": false,
    "view_count": 64,
    "answer_count": 1,
    "score": 0,
    "last_activity_date": 1757073997,
    "creation_date": 1757070223,
    "last_edit_date": 1757073997,
    "question_id": 79756715,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79756715/firebase-remote-model-downloader-not-working-in-android-studio",
    "title": "Firebase Remote Model Downloader not working in android studio",
    "body": "<p>I am following this firebaseML <a href=\"https://firebase.google.com/docs/ml/android/use-custom-models#java\" rel=\"nofollow noreferrer\">guide</a> from Google, but I was not able to import my firebase custom text classifier model into my android studio. I don't understand why since my model is only 12.5 mb.</p>\n<p>here is the code:</p>\n<pre><code>Interpreter interpreter;\nprivate volatile boolean isInitialized = false;\n\n// countdown incase of slow download\nprivate CountDownLatch initLatch = new CountDownLatch(1);\n\npublic void initTextModel(Context context, String textModelName) throws IOException {\n    this.mcontext = context;\n    downloadModel();\n    try {\n        boolean success = initLatch.await(30, TimeUnit.SECONDS);\n        if (!success) {\n            throw new IOException(&quot;Model download timeout took longer than 60s&quot;);\n        }\n        if (!isInitialized) {\n            throw new IOException(&quot;Model initialization failed&quot;);\n        }\n        Log.i(TAG, &quot;Text model initialization completed successfully&quot;);\n    } catch (InterruptedException e) {\n        throw new IOException(&quot;Model initialization interrupted&quot;, e);\n    }\n}\n\nprivate synchronized void downloadModel() {\n    Log.w(TAG, &quot;downloadModel: downloading model...&quot; );\n    CustomModelDownloadConditions conditions = new CustomModelDownloadConditions.Builder()\n            .requireWifi()  // Also possible: .requireCharging() and .requireDeviceIdle()\n            .build();\n    FirebaseModelDownloader.getInstance()\n            .getModel(&quot;exporter_text_model&quot;, DownloadType.LOCAL_MODEL_UPDATE_IN_BACKGROUND, conditions)\n            .addOnSuccessListener(new OnSuccessListener&lt;CustomModel&gt;() {\n                @Override\n                public void onSuccess(CustomModel model) {\n                    // Download complete. Depending on your app, you could enable the ML\n                    // feature, or switch from the local model to the remote model, etc.\n\n                    // The CustomModel object contains the local path of the model file,\n                    // which you can use to instantiate a TensorFlow Lite interpreter.\n                    File modelFile = model.getFile();\n                    if (modelFile != null) {\n                        interpreter = new Interpreter(modelFile);\n                    }\n                    Log.w(TAG, &quot;onSuccess: Model downloaded&quot; );\n                    initLatch.countDown();\n                }\n            });\n\n}\n</code></pre>\n<p>Solutions I tried:</p>\n<ul>\n<li>added a latch fallback but the download time exceeds more than a minute.</li>\n<li>At first I thought the problem is the wifi access so I added <code>&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot; /&gt;</code>, however it still did not fix the problem.</li>\n</ul>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}