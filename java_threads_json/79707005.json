{
  "question": {
    "tags": [
      "python",
      "java",
      "apache-spark",
      "pyspark",
      "pyspark-pandas"
    ],
    "owner": {
      "account_id": 16967464,
      "reputation": 27,
      "user_id": 12272959,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/a5bd508c68ff2ba03a52b51c838f0a7f?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "Node98",
      "link": "https://stackoverflow.com/users/12272959/node98"
    },
    "is_answered": false,
    "view_count": 252,
    "answer_count": 1,
    "score": 0,
    "last_activity_date": 1753081142,
    "creation_date": 1752906934,
    "last_edit_date": 1752981311,
    "question_id": 79707005,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79707005/not-able-to-run-a-spark-code-due-to-some-issue-on-my-local",
    "title": "Not able to run a spark code due to some issue on my local",
    "body": "<p>I am facing the below error while running the given piece of spark code on my local Pycharm Community Edition and the spark session is not getting created.\nI have set up all my local environment variable correctly for jdk and spark both.\nFYI I am using java &quot;openjdk 11.0.22 2024-01-16&quot;, &quot;javac 11.0.22&quot;, Python 3.13.5 and pyspark 3.5.6 versions. Could someone please help me to solve this issue.\nThanks in Advance!!!</p>\n<pre><code>from pyspark.sql import functions as f\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import session_window\nfrom pyspark.sql import Window\nimport os\nimport findspark\n\nfindspark.init(&quot;C:\\\\spark&quot;)\nos.environ[&quot;JAVA_HOME&quot;] = &quot;C:\\\\Program Files\\\\Eclipse Adoptium\\\\jdk-11.0.22.7-hotspot&quot;\nos.environ[&quot;SPARK_HOME&quot;] = &quot;C:\\\\spark&quot;\nprint(&quot;Pyspark Imported&quot;)\nspark = SparkSession.builder.appName(&quot;CSVEXAMPLE&quot;).getOrCreate()\n\nprint(&quot;spark sessions started&quot;)\nprint(&quot;Spark Version:&quot;, spark.version)\n</code></pre>\n<p>The <strong>&quot;Pyspark Imported&quot;</strong> line is only getting printed then the below error is coming.</p>\n<p><strong>Error:</strong></p>\n<pre class=\"lang-none prettyprint-override\"><code>File &quot;C:\\Users\\pythonProject\\TEST_SCRIPT.py&quot;, line 11, in &lt;module&gt;\n \nspark = SparkSession.builder.appName(&quot;CSVEXAMPLE&quot;).getOrCreate()\n \nFile &quot;C:\\Users\\pythonProject\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py&quot;,\nline 559, in getOrCreate\n \nsession = SparkSession(sc, options=self._options)\n \nFile &quot;C:\\Users\\pythonProject\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py&quot;,\nline 635, in __init__\n \njSparkSessionClass.getDefaultSession().isDefined()\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n \nTypeError: 'JavaPackage' object is not callable\n\nProcess finished with exit code 1\n</code></pre>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}