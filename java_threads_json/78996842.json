{
  "question": {
    "tags": [
      "java",
      "apache-spark",
      "apache-spark-sql",
      "parquet"
    ],
    "owner": {
      "account_id": 7249319,
      "reputation": 1,
      "user_id": 9444970,
      "user_type": "registered",
      "profile_image": "https://i.sstatic.net/VtSWu.jpg?s=256",
      "display_name": "Rohan Gala",
      "link": "https://stackoverflow.com/users/9444970/rohan-gala"
    },
    "is_answered": false,
    "view_count": 112,
    "answer_count": 1,
    "score": 0,
    "last_activity_date": 1726951383,
    "creation_date": 1726641527,
    "last_edit_date": 1726682904,
    "question_id": 78996842,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/78996842/parquet-partition-strategy-for-single-small-file-and-read-optimization",
    "title": "Parquet Partition Strategy for single small file and read Optimization",
    "body": "<p>I have single parquet file ranging from 5 to 100Mb of Data.</p>\n<p>While i tried to create partition on Date column multiple files are getting created which reduces the read performance as there are many small files.</p>\n<p>Hence i used repartition(1) to create only single file.</p>\n<p>Now the query used on this file using Spark sql is date range query like date between x and y.</p>\n<pre><code>public DataFilter applyValuationDateRangeFilter() {\n    AlcyoneDate startDate = calculationContext.getDateSequence().getStartDate();\n    AlcyoneDate endDate = calculationContext.getDateSequence().getEndDate();\n    filterQueries.append(&quot; AND &quot;);\n    filterQueries.append(&quot;ValuationDate BETWEEN '&quot;).append(startDate).append(&quot;' AND     '&quot;).append(endDate).append(&quot;'&quot;);\n    return this;\n}\n</code></pre>\n<p>I tried to create partition on ValuationDate column with repartition(1) but didnt get much benefit.</p>\n<p>How do i increase my read performance?</p>\n<p>I am applying the filter at the time of file loading:</p>\n<pre><code>public  Dataset&lt;Row&gt; getDatasetForInputFileWithFiltering(String parquetFilePath, String filterQuery) {\n    return getSparkSession().read().format(&quot;parquet&quot;)\n            .option(&quot;inferSchema&quot;, &quot;true&quot;)\n            .option(&quot;header&quot;, &quot;true&quot;)\n            .load(parquetFilePath)\n            .filter(filterQuery);\n}\n</code></pre>\n<p>Also i need to iterate over all the rows to populate some data:</p>\n<pre><code>Iterator&lt;Row&gt; rowIterator = rows.toLocalIterator();\n        while (rowIterator.hasNext()) {\n            Row row = rowIterator.next();\n</code></pre>\n<p>I am not able to use rows.collectAsList() as it is giving me OOM.\nAlso not able to use rows.foreach and rows.foreachPartition as my downstream code is not multi threading handled.</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}