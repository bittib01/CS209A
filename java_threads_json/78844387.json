{
  "question": {
    "tags": [
      "java",
      "apache-kafka",
      "zstd"
    ],
    "owner": {
      "account_id": 30394839,
      "reputation": 1,
      "user_id": 23292726,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/30281456b41a6648ff805a5428f16ab8?s=256&d=identicon&r=PG",
      "display_name": "Michele",
      "link": "https://stackoverflow.com/users/23292726/michele"
    },
    "is_answered": true,
    "view_count": 2108,
    "answer_count": 2,
    "score": 0,
    "last_activity_date": 1724521465,
    "creation_date": 1723042607,
    "last_edit_date": 1724521465,
    "question_id": 78844387,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/78844387/upgrading-apache-kafka-client-to-3-8-0-issue",
    "title": "Upgrading Apache Kafka client to 3.8.0 issue",
    "body": "<p>After upgrading the Apache Kafka client from <code>3.7.1</code> to <code>3.8.0</code> we ran into this <code>UnsatisfiedLinkError</code> during messages put on a topic:</p>\n<pre><code>java.lang.UnsatisfiedLinkError: /tmp/libzstd-jni-1.5.6-34907981766316087764.so: /tmp/libzstd-jni-1.5.6-34907981766316087764.so: failed to map segment from shared object: Operation not permitted\nno zstd-jni-1.5.6-3 in java.library.path\nUnsupported OS/arch, cannot find /linux/amd64/libzstd-jni-1.5.6-3.so or load zstd-jni-1.5.6-3 from system libraries. Please try building from source the jar or providing libzstd-jni-1.5.6-3 in your system.\n    at it.vtfinance.vtpie.core.process.StreamExecutor$2.doInTransactionWithoutResult(StreamExecutor.java:144)\n    at org.springframework.transaction.support.TransactionCallbackWithoutResult.doInTransaction(TransactionCallbackWithoutResult.java:36)\n    at org.springframework.transaction.support.TransactionTemplate.execute(TransactionTemplate.java:140)\n    at it.vtfinance.vtpie.core.process.StreamExecutor.executeTaskInPhase(StreamExecutor.java:120)\n    at it.vtfinance.vtpie.core.process.StreamExecutor.executePhase(StreamExecutor.java:184)\n    at it.vtfinance.vtpie.core.process.template.processor.StreamDataProcessor.process(StreamDataProcessor.java:48)\n    at it.vtfinance.vtpie.core.process.template.ProcessorTemplate$ProcessorTemplateWorker.execute(ProcessorTemplate.java:546)\n    at it.vtfinance.vtpie.core.work.AbstractWork.run(AbstractWork.java:70)\n    at org.jboss.jca.core.workmanager.WorkWrapper.runWork(WorkWrapper.java:445)\n    at org.jboss.as.connector.services.workmanager.WildflyWorkWrapper.runWork(WildflyWorkWrapper.java:69)\n    at org.jboss.jca.core.workmanager.WorkWrapper.run(WorkWrapper.java:223)\n    at org.jboss.threads.SimpleDirectExecutor.execute(SimpleDirectExecutor.java:29)\n    at org.jboss.threads.QueueExecutor.runTask(QueueExecutor.java:789)\n    at org.jboss.threads.QueueExecutor.access$100(QueueExecutor.java:44)\n    at org.jboss.threads.QueueExecutor$Worker.run(QueueExecutor.java:830)\n    at java.lang.Thread.run(Thread.java:750)\n    at org.jboss.threads.JBossThread.run(JBossThread.java:485)\n</code></pre>\n<p>This is caused by <code>/tmp</code> directory mounted with <code>noexec</code> property.</p>\n<p>I think that this is a side effect of the new compression level support feature.</p>\n<p>For security policy often in the production environment <code>/tmp</code> directories are mounted in <code>noexec</code> mode, there's a way to bypass this problem?</p>\n<p>Those are Kafka client parameter:</p>\n<pre><code>acks = -1\nauto.include.jmx.reporter = true\nbatch.size = 16384\nbootstrap.servers = [xxx:9093]\nbuffer.memory = 33554432\nclient.dns.lookup = use_all_dns_ips\nclient.id = producer-1\ncompression.gzip.level = -1\ncompression.lz4.level = 9\ncompression.type = none\ncompression.zstd.level = 3\nconnections.max.idle.ms = 540000\ndelivery.timeout.ms = 120000\nenable.idempotence = true\nenable.metrics.push = true\ninterceptor.classes = []\nkey.serializer = class org.apache.kafka.common.serialization.IntegerSerializer\nlinger.ms = 0\nmax.block.ms = 5000\nmax.in.flight.requests.per.connection = 5\nmax.request.size = 1048576\nmetadata.max.age.ms = 300000\nmetadata.max.idle.ms = 300000\nmetadata.recovery.strategy = none\nmetric.reporters = []\nmetrics.num.samples = 2\nmetrics.recording.level = INFO\nmetrics.sample.window.ms = 30000\npartitioner.adaptive.partitioning.enable = true\npartitioner.availability.timeout.ms = 0\npartitioner.class = null\npartitioner.ignore.keys = false\nreceive.buffer.bytes = 32768\nreconnect.backoff.max.ms = 1000\nreconnect.backoff.ms = 50\nrequest.timeout.ms = 30000\nretries = 2147483647\nretry.backoff.max.ms = 1000\nretry.backoff.ms = 100\nsasl.client.callback.handler.class = null\nsasl.jaas.config = null\nsasl.kerberos.kinit.cmd = /usr/bin/kinit\nsasl.kerberos.min.time.before.relogin = 60000\nsasl.kerberos.service.name = null\nsasl.kerberos.ticket.renew.jitter = 0.05\nsasl.kerberos.ticket.renew.window.factor = 0.8\nsasl.login.callback.handler.class = null\nsasl.login.class = null\nsasl.login.connect.timeout.ms = null\nsasl.login.read.timeout.ms = null\nsasl.login.refresh.buffer.seconds = 300\nsasl.login.refresh.min.period.seconds = 60\nsasl.login.refresh.window.factor = 0.8\nsasl.login.refresh.window.jitter = 0.05\nsasl.login.retry.backoff.max.ms = 10000\nsasl.login.retry.backoff.ms = 100\nsasl.mechanism = GSSAPI\nsasl.oauthbearer.clock.skew.seconds = 30\nsasl.oauthbearer.expected.audience = null\nsasl.oauthbearer.expected.issuer = null\nsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\nsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\nsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\nsasl.oauthbearer.jwks.endpoint.url = null\nsasl.oauthbearer.scope.claim.name = scope\nsasl.oauthbearer.sub.claim.name = sub\nsasl.oauthbearer.token.endpoint.url = null\nsecurity.protocol = SSL\nsecurity.providers = null\nsend.buffer.bytes = 131072\nsocket.connection.setup.timeout.max.ms = 30000\nsocket.connection.setup.timeout.ms = 10000\nssl.cipher.suites = null\nssl.enabled.protocols = [TLSv1.2]\nssl.endpoint.identification.algorithm = https\nssl.engine.factory.class = null\nssl.key.password = null\nssl.keymanager.algorithm = SunX509\nssl.keystore.certificate.chain = null\nssl.keystore.key = null\nssl.keystore.location = null\nssl.keystore.password = null\nssl.keystore.type = JKS\nssl.protocol = TLSv1.2\nssl.provider = null\nssl.secure.random.implementation = null\nssl.trustmanager.algorithm = PKIX\nssl.truststore.certificates = null\nssl.truststore.location = null\nssl.truststore.password = null\nssl.truststore.type = JKS\ntransaction.timeout.ms = 5000\ntransactional.id = null\nvalue.serializer = class org.apache.kafka.common.serialization.StringSerializer\n</code></pre>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}