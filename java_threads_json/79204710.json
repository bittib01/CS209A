{
  "question": {
    "tags": [
      "javascript",
      "java",
      "floating-point",
      "ieee-754"
    ],
    "owner": {
      "account_id": 8253432,
      "reputation": 394,
      "user_id": 6264832,
      "user_type": "registered",
      "accept_rate": 62,
      "profile_image": "https://i.sstatic.net/0azUJ.jpg?s=256",
      "display_name": "Isaac King",
      "link": "https://stackoverflow.com/users/6264832/isaac-king"
    },
    "is_answered": true,
    "view_count": 190,
    "answer_count": 2,
    "score": 2,
    "last_activity_date": 1737880094,
    "creation_date": 1732042371,
    "last_edit_date": 1732042833,
    "question_id": 79204710,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79204710/why-does-ieee-754-define-1-nan-as-1-and-why-do-java-and-javascript-violate-th",
    "title": "Why does IEEE 754 define 1 ^ NaN as 1, and why do Java and Javascript violate this?",
    "body": "<p>IEEE 754 defines 1 ^ n as 1, regardless of n. (I'm not <a href=\"https://store.accuristech.com/ieee/standards/ieee-754-2019?vendor_id=6210&amp;product_id=2033371\" rel=\"nofollow noreferrer\">paying $106</a> to confirm this for myself, but <a href=\"http://tom7.org/nand/nand.pdf\" rel=\"nofollow noreferrer\">this paper</a> cites page 44 from the 2008 standard for this claim.) Most programming languages seem to follow this prescription: Python, C, C#, PHP, Go, and Rust all return 1 for 1 ^ NaN. However, Java and Javascript both return NaN.</p>\n<ol>\n<li>Why does IEEE 754 create this exception to the general rule of NaN propagation?</li>\n<li>Why do Java and Javascript not follow the standard?</li>\n</ol>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}