{
  "question": {
    "tags": [
      "java",
      "scala",
      "maven",
      "apache-spark"
    ],
    "owner": {
      "account_id": 12077529,
      "reputation": 183,
      "user_id": 8830443,
      "user_type": "registered",
      "profile_image": "https://www.gravatar.com/avatar/08dd0c34f644150cf4972b3dc2cef46b?s=256&d=identicon&r=PG&f=y&so-version=2",
      "display_name": "saravana ir",
      "link": "https://stackoverflow.com/users/8830443/saravana-ir"
    },
    "is_answered": true,
    "view_count": 371,
    "accepted_answer_id": 79214908,
    "answer_count": 1,
    "score": 1,
    "last_activity_date": 1732277857,
    "creation_date": 1732270557,
    "last_edit_date": 1732277679,
    "question_id": 79214524,
    "content_license": "CC BY-SA 4.0",
    "link": "https://stackoverflow.com/questions/79214524/spark-scala-java-lang-nosuchfielderror-java-9-at-org-apache-spark-storage-sto",
    "title": "Spark Scala : java.lang.NoSuchFieldError: JAVA_9 at org.apache.spark.storage.StorageUtils$.&lt;init&gt;(StorageUtils.scala:207)",
    "body": "<p>I have a spark scala application, it uses the below versions(pasted only a section of the pom.xml) of dependencies and properties listed.</p>\n<p>Dependencies:</p>\n<pre><code>  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n  &lt;artifactId&gt;spark-hive_2.12&lt;/artifactId&gt;\n  &lt;version&gt;3.3.2&lt;/version&gt;\n\n  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n  &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt;\n  &lt;version&gt;3.3.2&lt;/version&gt;\n\n&lt;dependency&gt;\n  &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;\n  &lt;artifactId&gt;scala-reflect&lt;/artifactId&gt;\n  &lt;version&gt;2.12.10&lt;/version&gt;\n  &lt;scope&gt;compile&lt;/scope&gt;\n&lt;/dependency&gt;\n\n&lt;dependency&gt;\n  &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;\n  &lt;artifactId&gt;scala-compiler&lt;/artifactId&gt;\n  &lt;version&gt;2.12.10&lt;/version&gt;\n  &lt;scope&gt;compile&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre>\n<p>Properties:</p>\n<pre><code>&lt;scala.major.version&gt;2.12&lt;/scala.major.version&gt;\n&lt;scala.test.version&gt;3.2.18&lt;/scala.test.version&gt;\n&lt;scala.version&gt;2.12.18&lt;/scala.version&gt;\n\n&lt;maven.assembly.plugin.verion&gt;3.3.0&lt;/maven.assembly.plugin.verion&gt;\n&lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;\n&lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;\n&lt;maven.deploy.plugin.version&gt;2.8.2&lt;/maven.deploy.plugin.version&gt;\n&lt;maven.properties.plugin.verion&gt;1.0.0&lt;/maven.properties.plugin.verion&gt;\n&lt;maven.release.plugin.version&gt;3.0.0&lt;/maven.release.plugin.version&gt;\n&lt;maven.scala.plugin.version&gt;4.5.6&lt;/maven.scala.plugin.version&gt;\n&lt;maven.shade.plugin.version&gt;3.5.2&lt;/maven.shade.plugin.version&gt;\n&lt;maven.site.plugin.version&gt;3.12.1&lt;/maven.site.plugin.version&gt;\n&lt;maven.source.plugin.version&gt;3.2.1&lt;/maven.source.plugin.version&gt;\n</code></pre>\n<p>My local setup has java=1.8.0_202 and mvn=3.9.6</p>\n<p>I'm able to successfully compile the src/main and src/test --&gt; &quot;mvn test-compile&quot;.</p>\n<p>When I run &quot;mvn install&quot;, the unit tests start failing with the following error.</p>\n<pre class=\"lang-none prettyprint-override\"><code>*** RUN ABORTED ***\nAn exception or error caused a run to abort: JAVA_9 \n  java.lang.NoSuchFieldError: JAVA_9\n  at org.apache.spark.storage.StorageUtils$.&lt;init&gt;(StorageUtils.scala:207)\n  at org.apache.spark.storage.StorageUtils$.&lt;clinit&gt;(StorageUtils.scala)\n  at org.apache.spark.storage.BlockManagerMasterEndpoint.&lt;init&gt;(BlockManagerMasterEndpoint.scala:114)\n  at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:353)\n  at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:290)\n  at org.apache.spark.SparkEnv$.create(SparkEnv.scala:339)\n  at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:194)\n  at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:279)\n  at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:464)\n  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2714)\n</code></pre>\n<p>Kindly help me fix this. Also, I don't understand why does the control go into the &quot;if&quot; block of &quot;org.apache.spark.storage.StorageUtils$.(StorageUtils.scala:207)&quot; as the application is only compiled with Java 8.</p>\n"
  },
  "answers": [],
  "question_comments": [],
  "answer_comments": {}
}